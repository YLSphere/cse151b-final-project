{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091abbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\",\"miami\" ,\"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[:int(n * 0.8)]\n",
    "        \n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[:int(n * 0.8)]\n",
    "        \n",
    "    elif split == 'val':\n",
    "        f_in = ROOT_PATH + 'train' + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[int(n * 0.8):]\n",
    "        \n",
    "        f_out = ROOT_PATH + 'train' + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[int(n * 0.8):]\n",
    "    \n",
    "    elif split==\"test\":\n",
    "        f_in = ROOT_PATH + \"test\" + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        outputs = pickle.load(open(ROOT_PATH + 'train' + \"/\" + city + \"_outputs\", \"rb\")) #this isnt actually used\n",
    "        inputs = np.asarray(inputs)\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "city = 'palo-alto' \n",
    "split = 'train'\n",
    "train_dataset  = ArgoverseDataset(city = city, split = split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ba3fb04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(cities)):\n",
    "    train_dataset2=ArgoverseDataset(city = cities[i], split = split)\n",
    "    train_dataset=train_dataset+train_dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a174510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#city = 'austin' \n",
    "val_dataset = ArgoverseDataset(city = city, split = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ef27f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(cities)):\n",
    "    val_dataset2=ArgoverseDataset(city = cities[i], split = split)\n",
    "    val_dataset=val_dataset+val_dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a44d7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2399"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058453cc",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c14f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4  # batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee5b7ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "class Pred(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(100, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 120)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 100).float()\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        #print(x.shape)\n",
    "        x = x.reshape(-1, 60, 2)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1fb2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(torch.nn.Module):\n",
    " \n",
    "    def __init__(self):\n",
    "        super(Regression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(100, 120)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 100).float()\n",
    "        x = self.linear(x)\n",
    "        #print(x.shape)\n",
    "        x = x.reshape(-1,60,2)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3dd348d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        #self.drop= nn.Dropout(p=0.2)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, hn = self.rnn(x.float(), h0.detach())\n",
    "        #out=self.drop(out)\n",
    "        #print(out.shape)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        #print(out.shape)\n",
    "        out = out.reshape(-1,60,2)\n",
    "        #print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab8af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=0.01)\n",
    "        \n",
    "        #self.drop= nn.Dropout(p=0.2)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_dim)\n",
    "\n",
    "    def forward(self, x,hidden):\n",
    "        #h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        #x = x.transpose(0, 1)#.transpose(0, 1).to(device)\n",
    "        #print(x.shape)\n",
    "        x=x.float()\n",
    "        #out= self.fc(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        #out, hn = self.lstm(x.float(), h0.detach())\n",
    "        #out=self.drop(out)\n",
    "        print(out.shape)\n",
    "        out = F.relu(out)#.to(device)\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        #print(out.shape)\n",
    "        out = out.reshape(-1,60,2)\n",
    "        #print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "513027af",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cuda:0')\n",
    "input_size = 2\n",
    "hidden_size = 28#256\n",
    "output_size = 120\n",
    "batch_size = 4\n",
    "n_layers = 2\n",
    "seq_len = 50\n",
    "#epochs = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "70dbe82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(input_size, hidden_size, n_layers, output_size)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "adbc1d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = Regression()\n",
    "#opt = optim.Adam(pred.parameters(), lr=1e-4)\n",
    "def fitData(x, y, transform=\"MinMax\"):\n",
    "    if transform == 'MinMax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif transform == \"Standard\":\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        return x, y\n",
    "\n",
    "    scaler.fit(x.reshape(-1, 2))\n",
    "    scaler.fit(y.reshape(-1, 2))\n",
    "    x_ = scaler.transform(x.reshape(-1, 2)).reshape(-1, 50, 2)\n",
    "    y_ = scaler.transform(y.reshape(-1, 2)).reshape(-1, 60, 2)\n",
    "\n",
    "    return x_, y_, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "820398e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class min_max(object):\n",
    "    def __call__(self, tensor):\n",
    "        t_max=tensor.max(dim=1, keepdim=True)[0]\n",
    "        t_min=tensor.min(dim=1, keepdim=True)[0]\n",
    "        scale = 1.0 / (t_max - t_min) \n",
    "        tensor.mul_(scale).sub_(t_min)\n",
    "        return tensor,t_max,t_min,scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4725237",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 8810093.327367103\n",
      "epoch 1 loss: 366095.5533322186\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1364/1420526433.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs=[]\n",
    "losses=[]\n",
    "for epoch in range(100):\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, out = sample_batch\n",
    "        scaler=min_max()\n",
    "        #print(inp.shape)\n",
    "        #inp_scale,t_max,t_min,scale=scaler(inp)\n",
    "        #t_min=t_min.to(device)\n",
    "        #scale=scale.to(device)\n",
    "        #print(inp_scale.shape)\n",
    "        #inp_scale=inp_scale.reshape(-1,50,2)\n",
    "        preds = model(inp)\n",
    "        #print(preds)\n",
    "        #print(t_min)\n",
    "        #print(preds.shape)\n",
    "        #print(out.shape)\n",
    "        #print(t_min.shape)\n",
    "        #preds=preds.add_(t_min).div_(scale)\n",
    "        loss = ((preds - out) ** 2).sum()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    epochs.append(epoch)\n",
    "    losses.append(total_loss / len(train_dataset))\n",
    "    print('epoch {} loss: {}'.format(epoch, total_loss / len(train_dataset)))\n",
    "plt.plot(epochs,losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "#adam,.001,relu,batch=4, 73000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "8973f6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs[1:],losses[1:])\n",
    "plt.title(\"RNN Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "da57dc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 72688.15391001369\n"
     ]
    }
   ],
   "source": [
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz,shuffle=True)\n",
    "\n",
    "val_loss = 0\n",
    "for i_batch, sample_batch in enumerate(val_loader):\n",
    "    inp, out = sample_batch\n",
    "    #inp, out, scaler = fitData(inp, out, 'MinMax')\n",
    "    #inp=torch.from_numpy(inp)\n",
    "    #out=torch.from_numpy(out)\n",
    "    preds = model(inp)\n",
    "    \n",
    "    loss = ((preds - out) ** 2).sum()\n",
    "\n",
    "    val_loss += loss.item()\n",
    "print('loss: {}'.format(val_loss / len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10527012",
   "metadata": {},
   "outputs": [],
   "source": [
    "enumerate(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e07a1433",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ArgoverseDataset(city = \"palo-alto\", split = 'test')\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_sz,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "246a2bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1686"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7824baa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fede2989490>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e5bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f80b5e4",
   "metadata": {},
   "source": [
    "## Sample a batch of data and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6507c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1])\n",
    "        axs[i].scatter(out[i,:,0], out[i,:,1])\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    inp, out = sample_batch\n",
    "    print(inp.shape, out.shape)\n",
    "    break\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "      implement your Deep learning model\n",
    "      implement training routine\n",
    "    \"\"\"\n",
    "    show_sample_batch(sample_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30614c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c41b255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00333419",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cuda:0')\n",
    "input_size = 2\n",
    "hidden_size = 256\n",
    "output_size = 60\n",
    "batch_size = 4\n",
    "n_layers = 2\n",
    "seq_len = 50\n",
    "epochs = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74e20928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.c1 = nn.Conv1d(input_size, hidden_size, 2)\n",
    "        self.p1 = nn.MaxPool1d(4)\n",
    "        self.c2 = nn.Conv1d(hidden_size, hidden_size, 1)\n",
    "        self.p2 = nn.MaxPool1d(5)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=0.01)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        batch_size = inputs.shape[0]\n",
    "        \n",
    "\n",
    "        # Run through Conv1d and Pool1d layers\n",
    "        c = self.c1(inputs).to(device)\n",
    "        p = self.p1(c).to(device)\n",
    "        c = self.c2(p).to(device)\n",
    "        p = self.p2(c).to(device)\n",
    "        # Turn (batch_size x hidden_size x seq_len) back into (seq_len x batch_size x hidden_size) for RNN\n",
    "        p = p.transpose(1, 2).transpose(0, 1).to(device)\n",
    "        \n",
    "        p = F.relu(p)#.to(device)\n",
    "        output, hidden = self.lstm(p, hidden)\n",
    "        conv_seq_len = output.shape[0]\n",
    "        output = output.view(conv_seq_len * batch_size, self.hidden_size).to(device) # Treating (conv_seq_len x batch_size) as batch_size for linear layer\n",
    "#         output = torch.tanh(self.out(output))\n",
    "        output = self.out(output).to(device)\n",
    "        output = output.view( -1, self.output_size, conv_seq_len).to(device)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a99f30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size, hidden_size, output_size, n_layers=n_layers).to(device)\n",
    "optimizer = optim.Adam(rnn.parameters(), lr = 0.01)\n",
    "lossFunction = nn.MSELoss().to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da56074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
